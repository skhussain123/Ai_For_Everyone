{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb976636",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This Lecture introduces the Google AI Studio platform, its Gemini models, and how to utilize their APIs in Python. It emphasizes the advanced functionalities available in AI APIs, best practices for understanding and debugging code, and encourages a self-learning mindset for working with evolving AI platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f48e42",
   "metadata": {},
   "source": [
    "### 1. Advanced Features in AI APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56b103",
   "metadata": {},
   "source": [
    "**Multi-Turn Conversations and Chat Sessions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35c7b1",
   "metadata": {},
   "source": [
    "* APIs allow creating chat sessions where the model retains context of previous messages.\n",
    "* This enables conversational agents to maintain memory of prior interactions.\n",
    "* Configurable parameters include:\n",
    "  * max output length\n",
    "  * top P\n",
    "  * top K\n",
    "  * temperature (controls creativity/randomness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3c086",
   "metadata": {},
   "source": [
    "**Flexibility and Customization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1054b",
   "metadata": {},
   "source": [
    "* APIs provide multiple parameters and functionalities for:\n",
    "  * Experimentation with outputs.\n",
    "  * Tweaking model behavior.\n",
    "  * Creating different chat sessions.\n",
    "* Users must adapt API usage based on their specific needs and platform documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fcad14",
   "metadata": {},
   "source": [
    "**What is Google AI Studio?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf46f2c",
   "metadata": {},
   "source": [
    "* Centralized platform for Google‚Äôs AI services and models.\n",
    "* Google names its models Gemini.\n",
    "* Capabilities include:\n",
    "   * Text generation\n",
    "   * Conversational agents\n",
    "   * Content analysis and updates\n",
    "   * Multi-modal applications (handling different data types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0b251",
   "metadata": {},
   "source": [
    "**Setting Up Google Client in Python**<br>\n",
    "Install Google generative AI package:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53130b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b67ae",
   "metadata": {},
   "source": [
    "### How to Check Gemini Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important  the google generative AI Library\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API with your key \n",
    "genai.configure(api_key=\"AIzaSyCSn1aP0gMi_5VvJXOyCMy56XQjaMWUQ-c\")\n",
    "\n",
    "#List availabe models to verify our setup\n",
    "try:\n",
    "    models = genai.list_models()\n",
    "    gemini_models = [model.name for model in models if \"gemini\" in model.name.lower()]\n",
    "    print (\"Avaible Genimi models:\")\n",
    "    for model in gemini_models:\n",
    "        print(f\" -{model}\")\n",
    "    print(\"\\nGoogle AI STudio client configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Google AI studio client:{st(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"AIzaSyCSn1aP0gMi_5VvJXOyCMy56XQjaMWUQ-c\")\n",
    "\n",
    "def get_gemini_response(prompt):\n",
    "    try:\n",
    "        # Select the Gemini model\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "        # Generate a response\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the function\n",
    "prompt = \"Explain what an API is in one sentence.\"\n",
    "response = get_gemini_response(prompt)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff12dee",
   "metadata": {},
   "source": [
    "### Create a Chat Converstion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# üîê Step 1: Configure your API key\n",
    "genai.configure(api_key=\"AIzaSyCSn1aP0gMi_5VvJXOyCMy56XQjaMWUQ-c\")  # Replace with your actual API key\n",
    "\n",
    "# üß† Step 2: Create a Gemini chat session\n",
    "def chat_with_gemini():\n",
    "    \"\"\"\n",
    "    Function to start a chat session with the Gemini model and simulate a conversation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the model (e.g., 'gemini-1.5-pro' or 'gemini-1.5-flash')\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "        # Start a chat session with empty history\n",
    "        chat = model.start_chat(history=[])\n",
    "\n",
    "        # üó®Ô∏è Simulate a chat conversation\n",
    "        messages = [\n",
    "            \"Hello, who are you?\",\n",
    "            \"Can you explain what an API is?\",\n",
    "            \"Give me an example of a real-life API use.\",\n",
    "            \"Thanks! That's helpful.\"\n",
    "        ]\n",
    "\n",
    "        for msg in messages:\n",
    "            response = chat.send_message(msg)\n",
    "            print(f\"üë§ You: {msg}\")\n",
    "            print(f\"ü§ñ Gemini: {response.text}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# ‚ñ∂Ô∏è Run the chat\n",
    "chat_with_gemini()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
